"""
Main analysis script for both scenarios
"""

import os
import json
import PyPDF2
import google.generativeai as genai
from config import GEMINI_API_KEY, GEMINI_MODEL, PDF_FILES_PATH, SCORING_CRITERIA

# Configure Gemini API
genai.configure(api_key=GEMINI_API_KEY)

def extract_text_from_pdf(pdf_path):
    """Extract text content from a PDF file"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page in reader.pages:
                text += page.extract_text() + "\n"
        return text.strip()
    except Exception as e:
        return f"Error extracting text from {pdf_path}: {str(e)}"

def score_candidate_with_gemini(candidate_name, pdf_text):
    """Score a candidate using Gemini API directly"""
    model = genai.GenerativeModel(GEMINI_MODEL)
    
    prompt = f"""
    {SCORING_CRITERIA}
    
    Please analyze the following candidate submission for a Java developer role:
    
    Candidate: {candidate_name}
    Content:
    {pdf_text}
    
    Provide a score from 0-10 and detailed justification for your scoring based on the criteria above.
    Format your response as:
    Score: X/10
    Justification: [detailed explanation]
    """
    
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Error scoring candidate {candidate_name}: {str(e)}"

def simple_prompt_injection_check(text):
    """Simple prompt injection detection"""
    injection_patterns = [
        "ignore previous instructions",
        "ignore the above",
        "forget your role",
        "system override",
        "new instructions:",
        "ignore all above",
        "disregard the",
        "pay no attention to",
        "override system",
        "bypass security"
    ]
    
    text_lower = text.lower()
    detected_patterns = []
    
    for pattern in injection_patterns:
        if pattern in text_lower:
            detected_patterns.append(pattern)
    
    return detected_patterns

def run_analysis():
    """Run the complete analysis"""
    print("=== Java Developer Candidate Analysis ===\n")
    
    # Get list of PDF files
    pdf_files = [f for f in os.listdir(PDF_FILES_PATH) if f.endswith('.pdf')]
    pdf_files.sort()
    
    results = {
        "scenario_1_direct_scoring": {},
        "scenario_2_with_security_check": {}
    }
    
    for pdf_file in pdf_files:
        candidate_name = pdf_file.replace('.pdf', '')
        pdf_path = os.path.join(PDF_FILES_PATH, pdf_file)
        
        print(f"Processing {candidate_name}...")
        
        # Extract text from PDF
        pdf_text = extract_text_from_pdf(pdf_path)
        
        # Scenario 1: Direct scoring
        print(f"  Scenario 1: Direct scoring...")
        direct_score = score_candidate_with_gemini(candidate_name, pdf_text)
        results["scenario_1_direct_scoring"][candidate_name] = {
            "score_response": direct_score,
            "pdf_length": len(pdf_text)
        }
        
        # Scenario 2: With security check
        print(f"  Scenario 2: Security check then scoring...")
        detected_injections = simple_prompt_injection_check(pdf_text)
        
        if detected_injections:
            security_result = f"SECURITY ALERT: Potential prompt injection detected. Patterns found: {', '.join(detected_injections)}. Scoring blocked for security."
            results["scenario_2_with_security_check"][candidate_name] = {
                "security_check": "FAILED",
                "detected_patterns": detected_injections,
                "score_response": security_result,
                "pdf_length": len(pdf_text)
            }
        else:
            # Safe to score
            protected_score = score_candidate_with_gemini(candidate_name, pdf_text)
            results["scenario_2_with_security_check"][candidate_name] = {
                "security_check": "PASSED",
                "detected_patterns": [],
                "score_response": protected_score,
                "pdf_length": len(pdf_text)
            }
        
        print(f"  Completed {candidate_name}\n")
    
    # Save results to file
    with open('analysis_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # Print summary comparison
    print("="*60)
    print("ANALYSIS SUMMARY")
    print("="*60)
    
    print("\nSCENARIO 1 - Direct Scoring (No Security Check):")
    print("-"*50)
    for candidate, result in results["scenario_1_direct_scoring"].items():
        # Extract score from response
        score_line = result['score_response'].split('\\n')[0] if 'Score:' in result['score_response'] else "Score not found"
        print(f"{candidate}: {score_line}")
    
    print("\nSCENARIO 2 - With Security Check:")
    print("-"*50)
    for candidate, result in results["scenario_2_with_security_check"].items():
        if result['security_check'] == 'FAILED':
            print(f"{candidate}: BLOCKED - {len(result['detected_patterns'])} injection patterns detected")
        else:
            score_line = result['score_response'].split('\\n')[0] if 'Score:' in result['score_response'] else "Score not found"
            print(f"{candidate}: {score_line}")
    
    print("\nSECURITY ANALYSIS:")
    print("-"*50)
    
    security_issues_found = []
    clean_submissions = []
    
    for candidate, result in results["scenario_2_with_security_check"].items():
        if result['security_check'] == 'FAILED':
            security_issues_found.append({
                'candidate': candidate,
                'patterns': result['detected_patterns']
            })
        else:
            clean_submissions.append(candidate)
    
    if security_issues_found:
        print("ðŸš¨ SECURITY ISSUES DETECTED:")
        for issue in security_issues_found:
            print(f"  - {issue['candidate']}: {', '.join(issue['patterns'])}")
    
    if clean_submissions:
        print("âœ… CLEAN SUBMISSIONS:")
        for candidate in clean_submissions:
            print(f"  - {candidate}")
    
    print(f"\nDetailed results saved to: analysis_results.json")
    
    return results

if __name__ == "__main__":
    results = run_analysis()